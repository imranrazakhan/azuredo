apiVersion: argoproj.io/v1alpha1
kind: CronWorkflow
metadata:
  name: etl-cron-workflow
  namespace: argo
spec:
  schedule: "0 13 * * *"  # Runs every day at 13:00 UTC
  concurrencyPolicy: "Replace"  # Ensures only one job runs at a time
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  startingDeadlineSeconds: 60  # Ensures the job starts within 60 sec if missed
  workflowSpec:
    entrypoint: etl-pipeline
    templates:
      - name: etl-pipeline
        steps:
          - - name: extract
              template: extract-step
          - - name: transform
              template: transform-step
          - - name: load
              template: load-step

      - name: extract-step
        container:
          image: python:3.9
          command: [python, -c]
          args:
            - |
              import requests
              import json
              response = requests.get('https://api.example.com/data')
              with open('/mnt/data/extracted.json', 'w') as f:
                  json.dump(response.json(), f)

      - name: transform-step
        container:
          image: python:3.9
          command: [python, -c]
          args:
            - |
              import json
              with open('/mnt/data/extracted.json') as f:
                  data = json.load(f)
              transformed = [{"id": d["id"], "value": d["value"] * 2} for d in data]
              with open('/mnt/data/transformed.json', 'w') as f:
                  json.dump(transformed, f)

      - name: load-step
        container:
          image: python:3.9
          env:
            - name: POSTGRES_HOST
              value: "<your-db-name>.postgres.database.azure.com"
            - name: POSTGRES_DB
              value: "yourdatabase"
            - name: AZURE_CLIENT_ID
              value: "<IDENTITY_ID>"  # AKS Managed Identity Client ID
          command: [python, -c]
          args:
            - |
              import os
              import psycopg2
              import json
              import subprocess
  
              # Get Azure AD token for PostgreSQL
              result = subprocess.run(
                  ["az", "account", "get-access-token", "--resource", "https://ossrdbms-aad.database.windows.net", "--query", "accessToken", "--output", "tsv"],
                  capture_output=True, text=True
              )
              access_token = result.stdout.strip()
  
              # Connect to PostgreSQL using the access token
              conn = psycopg2.connect(
                  dbname=os.getenv("POSTGRES_DB"),
                  user="aks_etl_user",
                  password=access_token,
                  host=os.getenv("POSTGRES_HOST"),
                  sslmode="require"
              )
  
              cursor = conn.cursor()
  
              # Load data from transformed.json
              with open('/mnt/data/transformed.json') as f:
                  data = json.load(f)
  
              for item in data:
                  cursor.execute("INSERT INTO your_table (id, value) VALUES (%s, %s)", (item["id"], item["value"]))
  
              conn.commit()
              cursor.close()
              conn.close()
  
